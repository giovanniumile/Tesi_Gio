{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D con e senza drift usando mu_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "n_simulations = 10000  # Number of simulations\n",
    "n_steps = 100  # Steps in each trajectory\n",
    "mu_x_true = 0.2\n",
    "std_dev_x_true = 1 \n",
    "\n",
    "def compute_log_likelihood(x_steps, mu_x, std_dev_x):\n",
    "    \"\"\"Compute log-likelihood for a given trajectory.\"\"\"\n",
    "    log_likelihood_x = np.sum(norm.logpdf(x_steps, loc=mu_x, scale=std_dev_x))\n",
    "    return log_likelihood_x\n",
    "\n",
    "Lambda_values = []\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, n_steps)\n",
    "    \n",
    "    \n",
    "    #std_x_est = np.std(x_steps_observed)\n",
    "    #mu_x_est = np.mean(x_steps_observed)\n",
    "    log_likelihood_ML = compute_log_likelihood(\n",
    "        x_steps_observed, \n",
    "        mu_x=mu_x_true,\n",
    "        std_dev_x=std_dev_x_true\n",
    "    )\n",
    "\n",
    "    \n",
    "    log_likelihood_alt = compute_log_likelihood(\n",
    "        x_steps_observed, \n",
    "        mu_x=-mu_x_true,\n",
    "        std_dev_x=std_dev_x_true\n",
    "    )\n",
    "    \n",
    "    #KL = 2 * mu_x_est**2/std_x_est**2\n",
    "    Lambda = (log_likelihood_ML - log_likelihood_alt)/2 #capire perché c'è questo /2 anziché *2\n",
    "    Lambda_values.append(Lambda)\n",
    "\n",
    "x_range = np.linspace(0, max(Lambda_values), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "\n",
    "params = st.ncx2.fit(Lambda_values)\n",
    "chi2_pdf_fit = st.ncx2.pdf(x_range, *params)\n",
    "#chi2_pdf_fit = st.ncx2.pdf(x_range, lmd, dof)\n",
    "print(\"Fit parameters:\", params)\n",
    "print(Lambda_values)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$\")\n",
    "plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit, label=r\"Theoretical non central $\\chi^2()$\", color='green', alpha= 0.5, lw=2)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution and $\\chi^2(1)$, with $\\mu_x={mu_x_true}$ using $\\mu$ true\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D senza drift usando mu_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "n_simulations = 10000  # Number of simulations\n",
    "n_steps = 100  # Steps in each trajectory\n",
    "mu_x_true = 0.0\n",
    "std_dev_x_true = 1 \n",
    "\n",
    "def compute_log_likelihood(x_steps, mu_x, std_dev_x):\n",
    "    log_likelihood_x = np.sum(norm.logpdf(x_steps, loc=mu_x, scale=std_dev_x))\n",
    "    return log_likelihood_x\n",
    "\n",
    "Lambda_values = []\n",
    "KL_values = []\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    # Generate a trajectory under H0 (no drift)\n",
    "    x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, n_steps)\n",
    "    \n",
    "    # Log-likelihood (Maximum likelihood estimation)\n",
    "    std_x_est = np.std(x_steps_observed)\n",
    "    mu_x_est = np.mean(x_steps_observed)\n",
    "    log_likelihood_ML = compute_log_likelihood(\n",
    "        x_steps_observed, \n",
    "        mu_x=mu_x_est,\n",
    "        std_dev_x=std_x_est\n",
    "    )\n",
    "\n",
    "     # Log-likelihood under H0\n",
    "    log_likelihood_alt = compute_log_likelihood(\n",
    "        x_steps_observed, \n",
    "        mu_x=-mu_x_est,\n",
    "        std_dev_x=std_x_est\n",
    "    )\n",
    "    \n",
    "    KL = 2 * mu_x_est**2/std_x_est**2\n",
    "    KL_values.append(KL)\n",
    "    Lambda = (log_likelihood_ML - log_likelihood_alt)/2 #capire perché c'è questo /2 anziché *2\n",
    "    Lambda_values.append(Lambda)\n",
    "\n",
    "KL_media = np.mean(KL_values)\n",
    "print(f\"KL stimata= {KL_media}\")\n",
    "x_range = np.linspace(0, max(Lambda_values), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "Lambda_media = np.mean(Lambda_values)\n",
    "print(f\"Lambda media= {Lambda_media}\")\n",
    "\n",
    "params = st.ncx2.fit(Lambda_values)\n",
    "chi2_pdf_fit = st.ncx2.pdf(x_range, *params)\n",
    "#chi2_pdf_fit = st.ncx2.pdf(x_range, lmd, dof)\n",
    "print(\"Fit parameters:\", params)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$\")\n",
    "plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "#plt.plot(x_range, chi2_pdf_fit, label=r\"Theoretical non central $\\chi^2(2)$\", color='red', lw=2)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution and $\\chi^2(1)$, with $\\mu_x={mu_x_true}$\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D con drift usando mu_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\"\"\" per ora accantiniamo queste celle fatte con i cicli for\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "n_simulations = 10000  # Number of simulations\n",
    "n_steps = 100  # Steps in each trajectory\n",
    "mu_x_true = 0.2\n",
    "std_dev_x_true = 1 \n",
    "\n",
    "def compute_log_likelihood(x_steps, mu_x, std_dev_x):\n",
    "    log_likelihood_x = np.sum(norm.logpdf(x_steps, loc=mu_x, scale=std_dev_x))\n",
    "    return log_likelihood_x\n",
    "\n",
    "Lambda_values = []\n",
    "KL_values = []\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    # Generate a trajectory under H0 (no drift)\n",
    "    x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, n_steps)\n",
    "    \n",
    "    # Log-likelihood (Maximum likelihood estimation)\n",
    "    std_x_est = np.std(x_steps_observed)\n",
    "    mu_x_est = np.mean(x_steps_observed)\n",
    "    log_likelihood_ML = compute_log_likelihood(\n",
    "        x_steps_observed, \n",
    "        mu_x=mu_x_est,\n",
    "        std_dev_x=std_x_est\n",
    "    )\n",
    "\n",
    "     # Log-likelihood under H0\n",
    "    log_likelihood_alt = compute_log_likelihood(\n",
    "        x_steps_observed, \n",
    "        mu_x=-mu_x_est,\n",
    "        std_dev_x=std_x_est\n",
    "    )\n",
    "    \n",
    "    KL = 2 * mu_x_est**2/std_x_est**2\n",
    "    KL_values.append(KL)\n",
    "    Lambda = (log_likelihood_ML - log_likelihood_alt)/2 #capire perché c'è questo /2 anziché *2\n",
    "    Lambda_values.append(Lambda)\n",
    "\n",
    "KL_media = np.mean(KL_values)\n",
    "print(f\"KL stimata= {KL_media}\")\n",
    "x_range = np.linspace(0, max(Lambda_values), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "Lambda_media = np.mean(Lambda_values)\n",
    "print(f\"Lambda media= {Lambda_media}\")\n",
    "\n",
    "params = st.ncx2.fit(Lambda_values)\n",
    "chi2_pdf_fit = st.ncx2.pdf(x_range, *params)\n",
    "#chi2_pdf_fit = st.ncx2.pdf(x_range, lmd, dof)\n",
    "print(\"Fit parameters:\", params)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$\")\n",
    "plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit, label=r\"Theoretical non central $\\chi^2(1)$\", color='green', alpha=0.5, lw=2)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution and $\\chi^2(1)$, with $\\mu_x={mu_x_true}$\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D con drift togliendo il ciclo for: vettorializziamo il codice tramite numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "n_simulations = 10000  # Numero di simulazioni\n",
    "n_steps = 100  # Passi nelle traiettorie\n",
    "mu_x_true = 0.2\n",
    "std_dev_x_true = 1 \n",
    "\n",
    "x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, (n_simulations, n_steps))\n",
    "\n",
    "#uso numpy e vettorializzo il codice, così non devo più fare il ciclo for\n",
    "mu_x_est = np.mean(x_steps_observed, axis=1)  \n",
    "std_x_est = np.std(x_steps_observed, axis=1, ddof=1)  \n",
    "log_likelihood_ML = np.sum(norm.logpdf(x_steps_observed, loc=mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "log_likelihood_alt = np.sum(norm.logpdf(x_steps_observed, loc=-mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "\n",
    "KL_values = 2 * (mu_x_est ** 2 / std_x_est ** 2)\n",
    "Lambda_values = (log_likelihood_ML - log_likelihood_alt) / 2  # Qui manteniamo il /2\n",
    "\n",
    "KL_media = np.mean(KL_values)\n",
    "Lambda_media = np.mean(Lambda_values)\n",
    "\n",
    "print(f\"KL stimata= {KL_media}\")\n",
    "print(f\"Lambda media= {Lambda_media}\")\n",
    "\n",
    "x_range = np.linspace(0, max(Lambda_values), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "\n",
    "params = st.ncx2.fit(Lambda_values)\n",
    "chi2_pdf_fit = st.ncx2.pdf(x_range, *params)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$\")\n",
    "plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit, label=r\"Theoretical non-central $\\chi^2(1)$\", color='green', alpha=0.5, lw=2)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution and $\\chi^2(1)$, with $\\mu_x={mu_x_true}$\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Fit parameters for non-central chi-squared distribution:\", params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D senza ciclo for senza drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "n_simulations = 10000  # Numero di simulazioni\n",
    "n_steps = 100  # Passi nelle traiettorie\n",
    "mu_x_true = 0.\n",
    "std_dev_x_true = 1 \n",
    "\n",
    "x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, (n_simulations, n_steps))\n",
    "\n",
    "#uso numpy e vettorializzo il codice, così non devo più fare il ciclo for\n",
    "mu_x_est = np.mean(x_steps_observed, axis=1)  \n",
    "std_x_est = np.std(x_steps_observed, axis=1, ddof=1)  \n",
    "log_likelihood_ML = np.sum(norm.logpdf(x_steps_observed, loc=mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "log_likelihood_alt = np.sum(norm.logpdf(x_steps_observed, loc=-mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "\n",
    "KL_values = 2 * (mu_x_est ** 2 / std_x_est ** 2)\n",
    "Lambda_values = (log_likelihood_ML - log_likelihood_alt) / 2  # Qui manteniamo il /2\n",
    "\n",
    "KL_media = np.mean(KL_values)\n",
    "Lambda_media = np.mean(Lambda_values)\n",
    "\n",
    "print(f\"KL stimata= {KL_media}\")\n",
    "print(f\"Lambda media= {Lambda_media}\")\n",
    "\n",
    "x_range = np.linspace(0, max(Lambda_values), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "\n",
    "params = st.ncx2.fit(Lambda_values)\n",
    "chi2_pdf_fit = st.ncx2.pdf(x_range, *params)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$\")\n",
    "plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit, label=r\"Theoretical non-central $\\chi^2(1)$\", color='green', alpha=0.5, lw=2)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution and $\\chi^2(1)$, with $\\mu_x={mu_x_true}$\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Fit parameters for non-central chi-squared distribution:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D con drif usando XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import chi2\n",
    "from xgboost import XGBClassifier\n",
    "import time_irreversibility_estimator as ie\n",
    "\n",
    "\n",
    "n_simulations = 10000  # Numero di simulazioni\n",
    "n_steps = 100  # Passi nelle traiettorie\n",
    "mu_x_true = 0.0\n",
    "std_dev_x_true = 1 \n",
    "\n",
    "x_forward = np.cumsum(np.random.normal(mu_x_true, std_dev_x_true, (n_simulations, n_steps)), axis=1)\n",
    "#x_backward = np.cumsum(np.random.normal(-mu_x_true, std_dev_x_true, (n_simulations, n_steps)), axis=1)\n",
    "x_backward= -x_forward\n",
    "\n",
    "X = np.vstack((x_forward, x_backward))  # Feature: intere traiettorie\n",
    "y = np.concatenate((np.ones(n_simulations), np.zeros(n_simulations)))  # Target: 1 = Forward, 0 = Backward\n",
    "\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X, y)\n",
    "\n",
    "#ATTENZIONE: se prima potevo definire una funzione per calcolare le likelihood, ora non posso più farlo. Perché?\n",
    "#Perché la likelihood si può calcolare solo se si conosce la distribuzione di probabilità, e in questo caso non la conosco. In questo caso stimiamo la probabilità condiziona con il machine learning\n",
    "p_forward = clf.predict_proba(X)[:, 1]  # Probabilità stimata di forward\n",
    "\n",
    "Lambda_values = np.log(p_forward[:n_simulations]) - np.log(1 - p_forward[:n_simulations])\n",
    "\n",
    "x_range = np.linspace(0, max(Lambda_values), 500)\n",
    "chi2_pdf = chi2.pdf(x_range, df=1)\n",
    "\n",
    "params = st.ncx2.fit(Lambda_values)\n",
    "chi2_pdf_fit = st.ncx2.pdf(x_range, *params)\n",
    "\n",
    "#aggiungo lo stimatore di KL fatto da Chri\n",
    "encoding_fun = lambda x: np.diff(x, axis=0)\n",
    "estimator = ie.TimeIrreversibilityEstimator(interaction_constraints=None, verbose=True, random_state=0)\n",
    "irreversibility_value = estimator.fit_predict(x_forward=x_forward, x_backward=x_backward, encoding_fun=encoding_fun)\n",
    "print(f\"Estimated time irreversibility (KL): {irreversibility_value}\")\n",
    "print(f\"KL teorica = {2*mu_x_true**2/std_dev_x_true**2}\")\n",
    "\n",
    "# Plot dei risultati\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$\")\n",
    "plt.plot(x_range, chi2_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit, label=r\"Theoretical non-central $\\chi^2$\", color='blue', lw=2)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution and $\\chi^2(1)$, with $\\mu_x={mu_x_true}$ using Gradient Boosting\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Stampa dei parametri stimati della distribuzione non-centrale chi-quadro\n",
    "print(\"Fit parameters for non-central chi-squared distribution:\", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import chi2\n",
    "from xgboost import XGBClassifier\n",
    "import time_irreversibility_estimator as ie\n",
    "\n",
    "n_simulations = 10000  # Numero di simulazioni\n",
    "n_steps = 100  # Passi nelle traiettorie\n",
    "mu_x_true = 0.1\n",
    "std_dev_x_true = 1 \n",
    "\n",
    "x_forward = np.cumsum(np.random.normal(mu_x_true, std_dev_x_true, (n_simulations, n_steps)), axis=1)\n",
    "#x_backward = np.cumsum(np.random.normal(-mu_x_true, std_dev_x_true, (n_simulations, n_steps)), axis=1)\n",
    "x_backward= -x_forward\n",
    "\n",
    "X = np.vstack((x_forward, x_backward))  # Feature: intere traiettorie\n",
    "y = np.concatenate((np.ones(n_simulations), np.zeros(n_simulations)))  # Target: 1 = Forward, 0 = Backward\n",
    "\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X, y)\n",
    "\n",
    "#ATTENZIONE: se prima potevo definire una funzione per calcolare le likelihood, ora non posso più farlo. Perché?\n",
    "#Perché la likelihood si può calcolare solo se si conosce la distribuzione di probabilità, e in questo caso non la conosco. In questo caso stimiamo la probabilità condizionata con il machine learning\n",
    "p_forward = clf.predict_proba(X)[:, 1]  # Probabilità stimata di forward\n",
    "#p_backward = 1 - p_forward\n",
    "#p_backward = clf.predict_proba(X)[:, 0]  # Probabilità stimata di backward\n",
    "\n",
    "Lambda_values = np.log(p_forward[:n_simulations]) - np.log(1 - p_forward[:n_simulations]) #ATTENZIONE!!!!!Qui ci va il *2? il /2? o lasciamo così è un punto ancora irrisolto\n",
    "\n",
    "x_range = np.linspace(0, max(Lambda_values), 500)\n",
    "chi2_pdf = chi2.pdf(x_range, df=1)\n",
    "\n",
    "params = st.ncx2.fit(Lambda_values)\n",
    "chi2_pdf_fit = st.ncx2.pdf(x_range, *params)\n",
    "\n",
    "#aggiungo lo stimatore di KL fatto da Chri\n",
    "encoding_fun = lambda x: np.diff(x, axis=0)\n",
    "estimator = ie.TimeIrreversibilityEstimator(interaction_constraints=None, verbose=True, random_state=0)\n",
    "irreversibility_value = estimator.fit_predict(x_forward=x_forward, x_backward=x_backward, encoding_fun=encoding_fun)\n",
    "print(f\"Estimated time irreversibility (KL): {irreversibility_value}\")\n",
    "print(f\"KL teorica = {2*mu_x_true**2/std_dev_x_true**2}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$\")\n",
    "plt.plot(x_range, chi2_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit, label=r\"Theoretical non-central $\\chi^2$\", color='blue', lw=2)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution and $\\chi^2(1)$, with $\\mu_x={mu_x_true}$ using Gradient Boosting\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Stampa dei parametri stimati della distribuzione non-centrale chi-quadro (il primo parametro è il numero di gradi di libertà)\n",
    "print(\"Fit parameters for non-central chi-squared distribution:\", params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per essere consistenti, facciamo sia la stima con likelihood sia la stima con XGBoost su un n° di traiettorie pari a n_simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "n_simulations = 1000  # Numero di traiettorie (ogni traiettoria = un modello XGBoost)\n",
    "n_steps = 100  \n",
    "mu_x_true = 0.2  \n",
    "std_dev_x_true = 1  \n",
    "\n",
    "Lambda_values_likelihood = []\n",
    "Lambda_values_xgb = []\n",
    "KL_values_likelihood = []\n",
    "KL_values_xgb = []\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, n_steps)\n",
    "    mu_x_est = np.mean(x_steps_observed)\n",
    "    std_x_est = np.std(x_steps_observed, ddof=1)\n",
    "    \n",
    "    log_likelihood_ML = np.sum(norm.logpdf(x_steps_observed, loc=mu_x_est, scale=std_x_est))\n",
    "    log_likelihood_alt = np.sum(norm.logpdf(x_steps_observed, loc=-mu_x_est, scale=std_x_est))\n",
    "    \n",
    "    Lambda_likelihood = 2 * (log_likelihood_ML - log_likelihood_alt)/4\n",
    "    KL_likelihood = 2 * (mu_x_est**2 / std_x_est**2)\n",
    "\n",
    "    x_backward = -x_steps_observed  \n",
    "\n",
    "    X = np.concatenate((x_steps_observed.reshape(-1, 1), x_backward.reshape(-1, 1)), axis=0)\n",
    "    y = np.concatenate((np.ones(n_steps), np.zeros(n_steps)))  # Label: 1 = forward, 0 = backward\n",
    "\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', learning_rate=0.1, min_child_weight=10)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    p_forward = clf.predict_proba(x_steps_observed.reshape(-1, 1))[:, 1]  # P(F | forward)\n",
    "    p_backward = clf.predict_proba(x_backward.reshape(-1, 1))[:, 1]  # P(F | backward)\n",
    "\n",
    "    Lambda_xgb = 2 * np.sum(np.log(p_forward) - np.log(p_backward))/4\n",
    "\n",
    "    KL_xgb = np.mean(np.log(p_forward / p_backward))\n",
    "\n",
    "    Lambda_values_likelihood.append(Lambda_likelihood)\n",
    "    Lambda_values_xgb.append(Lambda_xgb)\n",
    "    KL_values_likelihood.append(KL_likelihood)\n",
    "    KL_values_xgb.append(KL_xgb)\n",
    "\n",
    "# Convertiamo in array per operazioni più veloci\n",
    "Lambda_values_likelihood = np.array(Lambda_values_likelihood)\n",
    "Lambda_values_xgb = np.array(Lambda_values_xgb)\n",
    "\n",
    "KL_values_likelihood = np.array(KL_values_likelihood)\n",
    "KL_values_xgb = np.array(KL_values_xgb)\n",
    "KL_media_likelihood = np.mean(KL_values_likelihood)\n",
    "KL_media_xgb = np.mean(KL_values_xgb)\n",
    "print(f\"KL stimata con likelihood= {KL_media_likelihood}\")\n",
    "print(f\"KL stimata con XGBoost= {KL_media_xgb}\")\n",
    "\n",
    "x_range = np.linspace(0, max(max(Lambda_values_likelihood), max(Lambda_values_xgb)), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "params_likelihood = st.ncx2.fit(Lambda_values_likelihood)\n",
    "params_xgb = st.ncx2.fit(Lambda_values_xgb)\n",
    "chi2_pdf_fit_likelihood = st.ncx2.pdf(x_range, *params_likelihood)\n",
    "chi2_pdf_fit_xgb = st.ncx2.pdf(x_range, *params_xgb)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_values_likelihood, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$ (Likelihood)\", color=\"blue\")\n",
    "plt.hist(Lambda_values_xgb, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$ (XGBoost)\", color=\"orange\")\n",
    "#plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit_likelihood, label=r\"Theoretical non-central $\\chi^2$ (Likelihood)\", color='green', lw=2, alpha=0.7)\n",
    "plt.plot(x_range, chi2_pdf_fit_xgb, label=r\"Theoretical non-central $\\chi^2$ (XGBoost)\", color='purple', lw=2, alpha=0.7)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution (Likelihood vs XGBoost), with $\\mu_x={mu_x_true}$\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora provo a eliminare il ciclo for e fare tutto  vettoriale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "n_simulations = 10000  \n",
    "n_steps = 100\n",
    "mu_x_true = 0.2\n",
    "std_dev_x_true = 1  \n",
    "\n",
    "x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, (n_simulations, n_steps))\n",
    "x_backward = -x_steps_observed  # Inversione temporale\n",
    "\n",
    "mu_x_est = np.mean(x_steps_observed, axis=1)  # Media per ogni traiettoria\n",
    "std_x_est = np.std(x_steps_observed, axis=1, ddof=1)  # Deviazione standard\n",
    "\n",
    "log_likelihood_ML = np.sum(norm.logpdf(x_steps_observed, loc=mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "log_likelihood_alt = np.sum(norm.logpdf(x_steps_observed, loc=-mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "\n",
    "Lambda_likelihood =  (log_likelihood_ML - log_likelihood_alt)/2\n",
    "KL_likelihood = 2 * (mu_x_est ** 2 / std_x_est ** 2)\n",
    "\n",
    "#XGBoost\n",
    "X = np.vstack((x_steps_observed.flatten().reshape(-1, 1), x_backward.flatten().reshape(-1, 1)))  # Feature: ogni punto della traiettoria separatamente\n",
    "y = np.concatenate((np.ones(n_simulations * n_steps), np.zeros(n_simulations * n_steps)))  # Target: 1 = forward, 0 = backward\n",
    "\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', learning_rate=0.1, min_child_weight=10)\n",
    "clf.fit(X, y)\n",
    "\n",
    "#ora non posso usare il rapporto tra likelihood, uso le probabilità condizionate P(F|q)\n",
    "p_forward = clf.predict_proba(x_steps_observed.flatten().reshape(-1, 1))[:, 1]  # P(F | forward)\n",
    "p_backward = clf.predict_proba(x_backward.flatten().reshape(-1, 1))[:, 1]  # P(F | backward)\n",
    "\n",
    "# Reshape corretto delle probabilità per adattarsi a (n_simulations, n_steps)\n",
    "p_forward = p_forward.reshape(n_simulations, n_steps)\n",
    "p_backward = p_backward.reshape(n_simulations, n_steps)\n",
    "\n",
    "Lambda_xgb = np.sum(np.log(p_forward) - np.log(p_backward), axis=1)/2\n",
    "KL_xgb = np.mean(np.log(p_forward / p_backward), axis=1)\n",
    "KL_media_likelihood = np.mean(KL_likelihood)\n",
    "KL_media_xgb = np.mean(KL_xgb) \n",
    "print(f\"KL stimata con likelihood= {KL_media_likelihood}\")\n",
    "print(f\"KL stimata con XGBoost= {KL_media_xgb}\")\n",
    "\n",
    "x_range = np.linspace(0, max(np.max(Lambda_likelihood), np.max(Lambda_xgb)), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "\n",
    "params_likelihood = st.ncx2.fit(Lambda_likelihood)\n",
    "params_xgb_gauss = st.norm.fit(Lambda_xgb)\n",
    "params_xgb = st.ncx2.fit(Lambda_xgb)\n",
    "\n",
    "chi2_pdf_fit_likelihood = st.ncx2.pdf(x_range, *params_likelihood)\n",
    "chi2_pdf_fit_xgb = st.ncx2.pdf(x_range, *params_xgb)\n",
    "gau_pdf_fit_xgb = st.norm.pdf(x_range, *params_xgb_gauss)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_likelihood, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$ (Likelihood)\", color=\"blue\")\n",
    "plt.hist(Lambda_xgb, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$ (XGBoost)\", color=\"orange\")\n",
    "#plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit_likelihood, label=r\"Theoretical non-central $\\chi^2$ (Likelihood)\", color='blue', lw=2, alpha=0.5)\n",
    "plt.plot(x_range, chi2_pdf_fit_xgb, label=r\"Theoretical non-central $\\chi^2$ (XGBoost)\", color='orange', lw=2, alpha=0.5)\n",
    "plt.plot(x_range, gau_pdf_fit_xgb, label=r\"Theoretical Gaussian (XGBoost)\", color='green', lw=2, alpha=0.5)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution (Likelihood vs XGBoost), with $\\mu_x={mu_x_true}$\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Gradient Boosting fit parameters for non-central chi-squared distribution:\", params_xgb)\n",
    "print(\"Gradient Boosting fit parameters for Gaussian distribution:\", params_xgb_gauss)\n",
    "\n",
    "print(\"Likelihood fit parameters for non-central chi-squared distribution:\", params_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora provo a usare la VERA formula di Lambda: $\\Lambda=2*(logL(alt)-logL(null)) ma verrà una distribuzione in Lambda negative..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm, chi2\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "n_simulations = 10000  \n",
    "n_steps = 100 \n",
    "mu_x_true = 0.1  \n",
    "std_dev_x_true = 1  \n",
    "\n",
    "x_steps_observed = np.random.normal(mu_x_true, std_dev_x_true, (n_simulations, n_steps))\n",
    "x_backward = -x_steps_observed  # Inversione temporale\n",
    "\n",
    "mu_x_est = np.mean(x_steps_observed, axis=1)  # Media per ogni traiettoria\n",
    "std_x_est = np.std(x_steps_observed, axis=1, ddof=1)  # Deviazione standard\n",
    "\n",
    "log_likelihood_ML = np.sum(norm.logpdf(x_steps_observed, loc=mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "log_likelihood_alt = np.sum(norm.logpdf(x_steps_observed, loc=-mu_x_est[:, None], scale=std_x_est[:, None]), axis=1)\n",
    "\n",
    "Lambda_likelihood =  2*(log_likelihood_alt - log_likelihood_ML)\n",
    "KL_likelihood = 2 * (mu_x_est ** 2 / std_x_est ** 2)\n",
    "\n",
    "#XGBoost\n",
    "X = np.vstack((x_steps_observed.flatten().reshape(-1, 1), x_backward.flatten().reshape(-1, 1)))  # Feature: ogni punto della traiettoria separatamente\n",
    "y = np.concatenate((np.ones(n_simulations * n_steps), np.zeros(n_simulations * n_steps)))  # Target: 1 = forward, 0 = backward\n",
    "\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', learning_rate=0.1, min_child_weight=10)\n",
    "clf.fit(X, y)\n",
    "\n",
    "#ora non posso usare il rapporto tra likelihood, uso le probabilità condizionate P(F|q)\n",
    "p_forward = clf.predict_proba(x_steps_observed.flatten().reshape(-1, 1))[:, 1]  # P(F | forward)\n",
    "p_backward = clf.predict_proba(x_backward.flatten().reshape(-1, 1))[:, 1]  # P(F | backward)\n",
    "\n",
    "# Reshape corretto delle probabilità per adattarsi a (n_simulations, n_steps)\n",
    "p_forward = p_forward.reshape(n_simulations, n_steps)\n",
    "p_backward = p_backward.reshape(n_simulations, n_steps)\n",
    "\n",
    "Lambda_xgb = np.sum(2*(np.log(p_backward)-np.log(p_forward)), axis=1)\n",
    "KL_xgb = np.mean(np.log(p_forward / p_backward), axis=1)\n",
    "KL_media_likelihood = np.mean(KL_likelihood)\n",
    "KL_media_xgb = np.mean(KL_xgb) \n",
    "print(f\"KL stimata con likelihood= {KL_media_likelihood}\")\n",
    "print(f\"KL stimata con XGBoost= {KL_media_xgb}\")\n",
    "\n",
    "x_range = np.linspace(0, max(np.max(Lambda_likelihood), np.max(Lambda_xgb)), 500)\n",
    "chi1_pdf = chi2.pdf(x_range, df=1)\n",
    "\n",
    "params_likelihood = st.ncx2.fit(Lambda_likelihood)\n",
    "params_xgb = st.ncx2.fit(Lambda_xgb)\n",
    "\n",
    "chi2_pdf_fit_likelihood = st.ncx2.pdf(x_range, *params_likelihood)\n",
    "chi2_pdf_fit_xgb = st.ncx2.pdf(x_range, *params_xgb)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Lambda_likelihood, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$ (Likelihood)\", color=\"blue\")\n",
    "plt.hist(Lambda_xgb, bins=100, density=True, alpha=0.6, label=\"Empirical $\\Lambda$ (XGBoost)\", color=\"orange\")\n",
    "#plt.plot(x_range, chi1_pdf, label=r\"Theoretical $\\chi^2(1)$\", color='red', lw=2)\n",
    "plt.plot(x_range, chi2_pdf_fit_likelihood, label=r\"Theoretical non-central $\\chi^2$ (Likelihood)\", color='blue', lw=2, alpha=0.5)\n",
    "plt.plot(x_range, chi2_pdf_fit_xgb, label=r\"Theoretical non-central $\\chi^2$ (XGBoost)\", color='orange', lw=2, alpha=0.5)\n",
    "\n",
    "plt.title(f\"Comparison of Empirical $\\Lambda$ Distribution (Likelihood vs XGBoost), with $\\mu_x={mu_x_true}$\")\n",
    "plt.xlabel(\"$\\Lambda$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Gradient Boosting fit parameters for non-central chi-squared distribution:\", params_xgb)\n",
    "print(\"Likelihood fit parameters for non-central chi-squared distribution:\", params_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Labo MICS/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolchristian2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
